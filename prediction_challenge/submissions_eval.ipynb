{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48879470-bd4e-4f23-b293-c8126cd7182e",
   "metadata": {},
   "source": [
    "# Housing Prices Prediction Challenge\n",
    "## Data Mining - Doctorado UDP 2025\n",
    "### Bastián González-Bustamante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a0ad6-11e3-4ec4-893d-2e457c7185dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "## from datetime import datetime\n",
    "\n",
    "## Submissions folder\n",
    "submissions_dir = 'submissions'\n",
    "results = []\n",
    "\n",
    "## Load training set and ground truth\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")  ## Load ground truth for test set, not available on GitHub\n",
    "\n",
    "## Discretise based on the training data only to avoid data leakage\n",
    "target = \"price_sqm\"\n",
    "labels_all = ['Low', 'Medium-Low', 'Medium', 'Medium-High', 'High']\n",
    "\n",
    "## Learn quantile bins on TRAIN ONLY\n",
    "_, bins = pd.qcut(y_train[target], q=5, retbins=True, duplicates='drop')\n",
    "bins[0], bins[-1] = -np.inf, np.inf\n",
    "labels = labels_all[:len(bins) - 1]\n",
    "\n",
    "# Apply the SAME thresholds\n",
    "y_train[target] = pd.cut(y_train[target], bins=bins, labels=labels, include_lowest=True)\n",
    "y_test[target]  = pd.cut(y_test[target], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "## Set the date based on participant and submission\n",
    "def get_dynamic_date(participant, submission):\n",
    "    if participant == \"Baseline\" and submission == \"1\":\n",
    "        return \"2025-11-06\"\n",
    "    elif participant == \"Victor\" and submission == \"1\":\n",
    "        return \"2025-11-06\"\n",
    "    elif participant == \"Luis\" and submission == \"1\":\n",
    "        return \"2025-11-06\" \n",
    "    elif participant == \"Dayana\" and submission == \"1\":\n",
    "        return \"2025-11-07\" \n",
    "    ## Add more submissions as needed\n",
    "    else:\n",
    "        return datetime.now().strftime(\"%Y-%m-%d\") \n",
    "\n",
    "## Mapping from numbers to labels\n",
    "label_mapping = {0: \"Low\", 1: \"Medium-Low\", 2: \"Medium\", 3: \"Medium-High\", 4: \"High\"}\n",
    "\n",
    "results = []\n",
    "\n",
    "for submission_file in os.listdir(submissions_dir):\n",
    "    if submission_file.endswith(\".csv\"):\n",
    "        ## Extract participant name, model name, and submission number from the file name\n",
    "        parts = submission_file.split(\"_\")\n",
    "        participant_name = parts[1]\n",
    "        model_name = parts[2]\n",
    "        submission_number = parts[3].split(\".\")[0]\n",
    "        \n",
    "        ## Load participant's submission\n",
    "        submission = pd.read_csv(os.path.join(submissions_dir, submission_file))\n",
    "\n",
    "        ## Numeric labels to categorical labels if necessary\n",
    "        if submission[\"predicted_label\"].dtype in [int, float]:\n",
    "            submission[\"predicted_label\"] = submission[\"predicted_label\"].map(label_mapping)\n",
    "\n",
    "        ## Compute metrics\n",
    "        accuracy = accuracy_score(y_test[\"price_sqm\"], submission[\"predicted_label\"])\n",
    "        precision = precision_score(y_test[\"price_sqm\"], submission[\"predicted_label\"], average=\"macro\")\n",
    "        recall = recall_score(y_test[\"price_sqm\"], submission[\"predicted_label\"], average=\"macro\")\n",
    "        f1 = f1_score(y_test[\"price_sqm\"], submission[\"predicted_label\"], average=\"macro\")\n",
    "        \n",
    "        ## Record results\n",
    "        results.append({\n",
    "            \"Participant\": participant_name,\n",
    "            \"Date\": get_dynamic_date(participant_name, submission_number),\n",
    "            \"Submission\": submission_number,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "## Sort by F1-Score\n",
    "leaderboard = pd.DataFrame(results)\n",
    "leaderboard = leaderboard.sort_values(by=\"F1-Score\", ascending=False)\n",
    "\n",
    "## Update Leaderboard\n",
    "leaderboard.to_csv(\"leaderboard.csv\", index=False)\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeabd6-bffd-4985-a4b8-a23117355b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
